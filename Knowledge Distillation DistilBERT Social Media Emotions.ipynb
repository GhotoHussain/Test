{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "\n",
    "import numpy as np # type: ignore # linear algebra\n",
    "import pandas as pd # type: ignore # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a classification label, with possible values including sadness (0), joy (1), love (2), anger (3), fear (4),surprise(5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emo_la={0:'neutral',1:'joy',2:'surprise',3:'anger',4:'sadness',5:'disgust',6:'fear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emo_la[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory_Data_Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data is in a CSV file\n",
    "df = pd.read_csv('SMED/Social Media Emotion Dataset.csv')\n",
    "\n",
    "# Rename Columns\n",
    "df.rename(columns={'text': 'Text', 'label': 'Label'}, inplace=True)\n",
    "\n",
    "# Dropping the Index Column if it exists\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Replace Label values\n",
    "#label_mapping = {0: 'Sadness', 1: 'Joy', 2: 'Love', 3: 'Anger', 4: 'Fear', 5: 'Surprise'}\n",
    "#df['Label'] = df['Label'].replace(label_mapping)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify changes\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names to ensure 'text' or 'Text' exists\n",
    "print(df.columns)\n",
    "\n",
    "# Locate duplicate text\n",
    "# Replace 'text' with the correct column name if necessary\n",
    "duplicated_texts = df[df.duplicated(subset='Text', keep=False)].sort_values(by='Text')\n",
    "\n",
    "# If there is duplicate text, process it\n",
    "if not duplicated_texts.empty:\n",
    "    # Keep only the 'Text' and 'Label' columns\n",
    "    duplicated_texts = duplicated_texts[['Text', 'Label']]\n",
    "    \n",
    "    # Drop duplicates in the 'Text' column, keeping the first occurrence\n",
    "    duplicated_texts = duplicated_texts.drop_duplicates(subset='Text', keep='first')\n",
    "    \n",
    "    # Drop the duplicate rows from the original DataFrame\n",
    "    df = df.drop(duplicated_texts.index)\n",
    "    \n",
    "    # Reset the index of the DataFrame\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check if there are any texts with multiple labels after processing\n",
    "duplicated_texts = df[df.duplicated(subset='Text', keep=False)].sort_values(by='Text')\n",
    "if not duplicated_texts.empty:\n",
    "    print(\"Texts with multiple labels:\")\n",
    "    print(duplicated_texts[['Text', 'Label']])\n",
    "else:\n",
    "    print(\"No duplicate text was found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming your data is already loaded into a DataFrame called `df`\n",
    "# If not, load your data as shown in the previous example\n",
    "\n",
    "# Value Count of Label\n",
    "count = df['Label'].value_counts()\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6), facecolor='white')\n",
    "\n",
    "# Plot pie chart on the first subplot\n",
    "palette = sns.color_palette(\"viridis\")\n",
    "sns.set_palette(palette)\n",
    "axs[0].pie(count, labels=count.index, autopct='%1.1f%%', startangle=140, colors=palette)\n",
    "axs[0].set_title('Distribution of Emotion Classes', fontsize=14)\n",
    "\n",
    "# Plot bar chart on the second subplot\n",
    "sns.barplot(x=count.index, y=count.values, hue=count.index, palette=\"viridis\", ax=axs[1], legend=False)\n",
    "axs[1].set_title('Distribution of Emotion Classes', fontsize=14)\n",
    "axs[1].set_xlabel('Emotion Classes', fontsize=12)\n",
    "axs[1].set_ylabel('Count', fontsize=12)\n",
    "axs[1].tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming your data is already loaded into a DataFrame called `df`\n",
    "# If not, load your data as shown in the previous example\n",
    "\n",
    "# Function to count words in a text\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Apply the word count function to the 'Text' column\n",
    "df['Word_Count'] = df['Text'].apply(count_words)\n",
    "\n",
    "# Group by 'Label' and sum the word counts\n",
    "word_count_per_class = df.groupby('Label')['Word_Count'].sum().reset_index()\n",
    "\n",
    "# Display the word count per class\n",
    "print(word_count_per_class)\n",
    "\n",
    "# Plot the word count per class\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Label', y='Word_Count', hue='Label', data=word_count_per_class, palette='viridis', legend=False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Emotion Classes', fontsize=14)\n",
    "plt.ylabel('Total Word Count', fontsize=14)\n",
    "plt.title('Total Word Count per Emotion Class', fontsize=16)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Assuming your data is already loaded into a DataFrame called `df`\n",
    "# If not, load your data as shown in the previous example\n",
    "\n",
    "# Function to count words in a text\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Apply the word count function to the 'Text' column\n",
    "df['Word_Count'] = df['Text'].apply(count_words)\n",
    "\n",
    "# Group by 'Label' and sum the word counts\n",
    "word_count_per_class = df.groupby('Label')['Word_Count'].sum().reset_index()\n",
    "\n",
    "# Create a Donut Chart\n",
    "fig = px.pie(word_count_per_class, values='Word_Count', names='Label', title='Word Count per Emotion Class (Donut Chart)', hole=0.4)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords (if not already downloaded)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Assuming your dataset is already loaded into a DataFrame called `df`\n",
    "# If not, load your data as shown in the previous example\n",
    "\n",
    "# Step 1: Remove URLs\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_urls)\n",
    "\n",
    "# Step 2: Remove special characters and punctuation\n",
    "def remove_special_chars(text):\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_special_chars)\n",
    "\n",
    "# Step 3: Remove extra whitespaces\n",
    "def remove_extra_whitespace(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_extra_whitespace)\n",
    "\n",
    "# Step 4: Remove numeric values\n",
    "def remove_numeric_values(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_numeric_values)\n",
    "\n",
    "# Step 5: Lowercasing\n",
    "df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "# Step 6: Remove stop words\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_stopwords)\n",
    "\n",
    "# Step 7: Remove non-alphanumeric characters\n",
    "def remove_non_alphanumeric(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_non_alphanumeric)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your cleaned DataFrame is stored in `df`\n",
    "# and it has two columns: 'Text' (features) and 'Label' (target)\n",
    "\n",
    "# Step 1: Split the data into training (70%) and temporary (30%) sets\n",
    "train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
    "    df['Text'],  # Features (text data)\n",
    "    df['Label'],  # Labels (target)\n",
    "    test_size=0.3,  # 30% of the data for temporary set\n",
    "    random_state=42  # Set a random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Step 2: Split the temporary data into validation (50%) and testing (50%) sets\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "    temp_data,  # Temporary features\n",
    "    temp_labels,  # Temporary labels\n",
    "    test_size=0.5,  # 50% of the temporary data for testing\n",
    "    random_state=42  # Set a random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Display the sizes of the resulting datasets\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Testing set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Split first\n",
    "train_texts, val_texts, train_y, val_y = train_test_split(\n",
    "    train_data, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    ")\n",
    "val_texts, test_texts, val_y, test_y = train_test_split(\n",
    "    val_texts, val_y, test_size=0.5, random_state=42, stratify=val_y\n",
    ")\n",
    "\n",
    "# 2) Back-translate ONLY train (example: augment minority label ids)\n",
    "minority_label_ids = [4]  # <-- replace with your minority class index(es), e.g. Surprise\n",
    "minority_idx = np.where(np.isin(train_y, minority_label_ids))[0]\n",
    "\n",
    "bt_texts = back_translate(train_texts[minority_idx].tolist())\n",
    "bt_labels = train_y[minority_idx]\n",
    "\n",
    "# 3) Combine original + augmented train\n",
    "train_texts_aug = np.concatenate([train_texts, np.array(bt_texts)], axis=0)\n",
    "train_y_aug = np.concatenate([train_y, bt_labels], axis=0)\n",
    "\n",
    "# 4) Save (after split + augmentation)\n",
    "pd.DataFrame({\"Text\": train_texts_aug, \"Label\": train_y_aug}).to_csv(\"train_data.csv\", index=False)\n",
    "pd.DataFrame({\"Text\": val_texts, \"Label\": val_y}).to_csv(\"val_data.csv\", index=False)\n",
    "pd.DataFrame({\"Text\": test_texts, \"Label\": test_y}).to_csv(\"test_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load translation models\n",
    "en_de_model_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
    "de_en_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "\n",
    "en_de_tokenizer = MarianTokenizer.from_pretrained(en_de_model_name)\n",
    "en_de_model = MarianMTModel.from_pretrained(en_de_model_name).to(device)\n",
    "\n",
    "de_en_tokenizer = MarianTokenizer.from_pretrained(de_en_model_name)\n",
    "de_en_model = MarianMTModel.from_pretrained(de_en_model_name).to(device)\n",
    "\n",
    "\n",
    "def translate(texts, model, tokenizer):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    translated = model.generate(**inputs, max_length=128)\n",
    "    return tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def back_translate(texts):\n",
    "    de_texts = translate(texts, en_de_model, en_de_tokenizer)\n",
    "    back_texts = translate(de_texts, de_en_model, de_en_tokenizer)\n",
    "    return back_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AlbertForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set CUDA_LAUNCH_BLOCKING=1 for debugging\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "epochs_teacher = 10  # Teacher training epochs\n",
    "epochs_student = 20  # Student training epochs\n",
    "initial_lr = 2e-5  # Initial learning rate for teacher\n",
    "student_lr = 1e-5  # Learning rate for student\n",
    "T = 1.5  # Temperature for soft targets\n",
    "alpha = 0.8  # Weight for knowledge distillation loss\n",
    "initial_weight_decay = 1e-2  # Weight decay\n",
    "patience = 5  # Early stopping patience\n",
    "max_grad_norm = 1.0  # Gradient clipping\n",
    "label_smoothing = 0.1  # Label smoothing\n",
    "\n",
    "# Assuming your dataset is already loaded into a DataFrame called `df`\n",
    "# Replace 'Text' and 'Label' with your actual column names\n",
    "train_data = df['Text'].values\n",
    "train_labels = df['Label'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Compute class weights for imbalanced data\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Initialize Tokenizer for BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Custom Dataset class for text input\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(val_texts, val_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n",
    "test_dataset = TextDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define Teacher and Student Models\n",
    "teacher_model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=5,  # Number of emotion classes\n",
    "    hidden_dropout_prob=0.3  # Dropout rate\n",
    ")\n",
    "\n",
    "# Change student model to ALBERT\n",
    "student_model = AlbertForSequenceClassification.from_pretrained(\n",
    "    'albert-base-v2',\n",
    "    num_labels=5,  # Number of emotion classes\n",
    "    output_hidden_states=True  # Enable hidden states\n",
    ")\n",
    "\n",
    "# Move models to GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "teacher_model.to(device)\n",
    "student_model.to(device)\n",
    "\n",
    "# Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Define Validation Function\n",
    "# ---------------------------\n",
    "def validate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Train Teacher Model\n",
    "# ---------------------------\n",
    "def train_teacher(model, train_loader, val_loader, epochs, lr):\n",
    "    model.train()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=initial_weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2)  # Use Focal Loss\n",
    "    scaler = GradScaler()  # For mixed precision training\n",
    "    best_val_loss = float('inf')\n",
    "    trigger_times = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Teacher Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            with autocast():  # Mixed precision training\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct / total * 100\n",
    "        print(f\"Teacher Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "        # Validate after each epoch\n",
    "        val_loss, val_accuracy = validate_model(model, val_loader)\n",
    "        scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Train Student Model with Knowledge Distillation\n",
    "# ---------------------------\n",
    "def train_student_with_kd(teacher_model, student_model, train_loader, epochs, lr, temperature, alpha):\n",
    "    student_model.train()\n",
    "    optimizer = optim.AdamW(student_model.parameters(), lr=lr, weight_decay=initial_weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2)  # Use Focal Loss\n",
    "    scaler = GradScaler()  # For mixed precision training\n",
    "    best_val_loss = float('inf')\n",
    "    trigger_times = 0\n",
    "\n",
    "    def kd_loss(student_logits, teacher_logits):\n",
    "        student_probs = torch.nn.functional.softmax(student_logits / temperature, dim=-1)\n",
    "        teacher_probs = torch.nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "        return torch.nn.functional.kl_div(student_probs.log(), teacher_probs, reduction='batchmean')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Student KD Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Teacher's output\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(input_ids, attention_mask=attention_mask)\n",
    "                teacher_logits = teacher_outputs.logits\n",
    "            \n",
    "            # Student's forward pass\n",
    "            with autocast():  # Mixed precision training\n",
    "                student_outputs = student_model(input_ids, attention_mask=attention_mask)\n",
    "                student_logits = student_outputs.logits\n",
    "                \n",
    "                # Compute losses\n",
    "                ce_loss = criterion(student_logits, labels)  # Standard loss\n",
    "                kd_loss_value = kd_loss(student_logits, teacher_logits)  # Knowledge distillation loss\n",
    "                total_loss = alpha * kd_loss_value + (1 - alpha) * ce_loss  # Combined loss\n",
    "                \n",
    "            scaler.scale(total_loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_grad_norm)  # Gradient clipping\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_loss += total_loss.item()\n",
    "            _, predicted = torch.max(student_logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        accuracy = correct / total * 100\n",
    "        print(f\"Student KD Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "        # Validate after each epoch\n",
    "        val_loss, val_accuracy = validate_model(student_model, val_loader)\n",
    "        scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "    \n",
    "    return student_model\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Evaluate Model\n",
    "# ---------------------------\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Compute additional evaluation metrics\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    \n",
    "    return accuracy, f1, precision, recall\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Run Training and Evaluation\n",
    "# ---------------------------\n",
    "# Train Teacher Model\n",
    "teacher_model = train_teacher(teacher_model, train_loader, val_loader, epochs_teacher, initial_lr)\n",
    "\n",
    "# Train Student Model with Knowledge Distillation\n",
    "student_model = train_student_with_kd(teacher_model, student_model, train_loader, epochs_student, student_lr, T, alpha)\n",
    "\n",
    "# Evaluate Teacher and Student Model on Test Data\n",
    "print(\"\\nTeacher Model Evaluation:\")\n",
    "evaluate_model(teacher_model, test_loader)\n",
    "\n",
    "print(\"\\nStudent Model Evaluation:\")\n",
    "evaluate_model(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_misclassified_examples(model, test_loader):\n",
    "    model.eval()\n",
    "    misclassified_examples = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Collecting Misclassified Examples\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                if predicted[i] != labels[i]:\n",
    "                    misclassified_examples.append({\n",
    "                        'text': tokenizer.decode(input_ids[i], skip_special_tokens=True),\n",
    "                        'true_label': label_encoder.inverse_transform([labels[i].cpu().numpy()])[0],\n",
    "                        'predicted_label': label_encoder.inverse_transform([predicted[i].cpu().numpy()])[0]\n",
    "                    })\n",
    "\n",
    "    return misclassified_examples\n",
    "\n",
    "# Collect misclassified examples for the student model\n",
    "misclassified_examples = collect_misclassified_examples(student_model, test_loader)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "misclassified_df = pd.DataFrame(misclassified_examples)\n",
    "print(misclassified_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text length to the DataFrame\n",
    "misclassified_df['text_length'] = misclassified_df['text'].apply(len)\n",
    "\n",
    "# Plot text length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(misclassified_df['text_length'], bins=30, kde=True)\n",
    "plt.title('Text Length Distribution for Misclassified Examples')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample of misclassified examples\n",
    "for i, row in misclassified_df.sample(5).iterrows():\n",
    "    print(f\"Text: {row['text']}\")\n",
    "    print(f\"True Label: {row['true_label']}\")\n",
    "    print(f\"Predicted Label: {row['predicted_label']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(model, test_loader):\n",
    "    model.eval()\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating Confusion Matrix\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_true_labels, all_predicted_labels)\n",
    "    class_names = label_encoder.classes_\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix for the student model\n",
    "plot_confusion_matrix(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def generate_classification_report(model, test_loader):\n",
    "    model.eval()\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating Predictions\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Generate classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(\n",
    "        all_true_labels,\n",
    "        all_predicted_labels,\n",
    "        target_names=label_encoder.classes_,\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    # Print accuracy\n",
    "    print(f\"Accuracy: {accuracy_score(all_true_labels, all_predicted_labels):.4f}\")\n",
    "    \n",
    "    # Print label mapping\n",
    "    print(\"\\nEmotion Label Mapping:\")\n",
    "    print(dict(enumerate(label_encoder.classes_)))\n",
    "\n",
    "# Example usage for student model\n",
    "print(\"Student Model Evaluation:\")\n",
    "generate_classification_report(student_model, test_loader)\n",
    "\n",
    "# Example usage for teacher model\n",
    "print(\"\\nTeacher Model Evaluation:\")\n",
    "generate_classification_report(teacher_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_misclassification_distribution(model, test_loader, label_encoder):\n",
    "    model.eval()\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating Predictions\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Create DataFrame for misclassifications\n",
    "    misclassified_df = pd.DataFrame({\n",
    "        'true_label': all_true_labels,\n",
    "        'predicted_label': all_predicted_labels\n",
    "    })\n",
    "\n",
    "    # Create a confusion matrix (cross-tab) of true vs predicted labels\n",
    "    cross_tab = pd.crosstab(misclassified_df['true_label'], misclassified_df['predicted_label'])\n",
    "\n",
    "    # Define the order of classes based on the actual labels in cross_tab\n",
    "    class_order = cross_tab.index.tolist()  # Use the exact labels from cross_tab\n",
    "\n",
    "    # Reorder the cross-tabulation based on the defined class order\n",
    "    cross_tab = cross_tab.loc[class_order, class_order]\n",
    "\n",
    "    # Remove the diagonal (correct predictions) to only show misclassifications\n",
    "    misclassified_tab = cross_tab.copy()\n",
    "    for i in range(len(misclassified_tab)):\n",
    "        misclassified_tab.iloc[i, i] = 0  # Set diagonal to 0 to exclude correct classifications\n",
    "\n",
    "    # Create a grouped bar plot for misclassifications only\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = misclassified_tab.plot(kind='bar', width=0.8, colormap='viridis', figsize=(14, 8))\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title('Misclassification Distribution: True Classes vs Predicted Classes (Student Model)', fontsize=16, pad=20)\n",
    "    plt.xlabel('True Label', fontsize=14)\n",
    "    plt.ylabel('Count of Misclassifications', fontsize=14)\n",
    "\n",
    "    # Customize legend to show predicted label names\n",
    "    class_names = {0: 'Angry', 1: 'Happy', 2: 'Neutral', 3: 'Sad', 4: 'Surprise'}\n",
    "    predicted_labels = [class_names[i] for i in misclassified_tab.columns]  # Mapping predicted indices to label names\n",
    "    plt.legend(title='Predicted Label', labels=predicted_labels, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
    "\n",
    "    # Map integer labels to class names for the x-axis\n",
    "    plt.xticks(ticks=range(len(misclassified_tab.index)), labels=[class_names[i] for i in misclassified_tab.index], rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Add gridlines for better visualization\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add data labels on top of bars\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\n",
    "            f\"{int(p.get_height())}\",  # Display the count as an integer\n",
    "            (p.get_x() + p.get_width() / 2, p.get_height()),  # Position of the label\n",
    "            ha='center', va='bottom',  # Alignment of the label\n",
    "            fontsize=10,  # Font size of the label\n",
    "            color='black'  # Color of the label\n",
    "        )\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for student model only\n",
    "print(\"Student Model Evaluation - Misclassification Distribution:\")\n",
    "generate_misclassification_distribution(student_model, test_loader, label_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_misclassification_distribution(model, test_loader, label_encoder):\n",
    "    model.eval()\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating Predictions\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Create DataFrame for misclassifications\n",
    "    misclassified_df = pd.DataFrame({\n",
    "        'true_label': all_true_labels,\n",
    "        'predicted_label': all_predicted_labels\n",
    "    })\n",
    "\n",
    "    # Create a confusion matrix (cross-tab) of true vs predicted labels\n",
    "    cross_tab = pd.crosstab(misclassified_df['true_label'], misclassified_df['predicted_label'])\n",
    "\n",
    "    # Define the order of classes based on the actual labels in cross_tab\n",
    "    class_order = cross_tab.index.tolist()  # Use the exact labels from cross_tab\n",
    "\n",
    "    # Reorder the cross-tabulation based on the defined class order\n",
    "    cross_tab = cross_tab.loc[class_order, class_order]\n",
    "\n",
    "    # Plot grouped bar plot with improved formatting\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = cross_tab.plot(kind='bar', width=0.8, colormap='viridis', figsize=(14, 8))\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title('Misclassification Distribution: True Classes vs Predicted Classes (Student Model)', fontsize=16, pad=20)\n",
    "    plt.xlabel('True Label', fontsize=14)\n",
    "    plt.ylabel('Count of Misclassifications', fontsize=14)\n",
    "\n",
    "    # Customize legend to show predicted label names\n",
    "    class_names = {0: 'Angry', 1: 'Happy', 2: 'Neutral', 3: 'Sad', 4: 'Surprise'}\n",
    "    predicted_labels = [class_names[i] for i in cross_tab.columns]  # Mapping predicted indices to label names\n",
    "    plt.legend(title='Predicted Label', labels=predicted_labels, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
    "\n",
    "    # Map integer labels to class names for the x-axis\n",
    "    plt.xticks(ticks=range(len(cross_tab.index)), labels=[class_names[i] for i in cross_tab.index], rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Add gridlines for better visualization\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add data labels on top of bars\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\n",
    "            f\"{int(p.get_height())}\",  # Display the count as an integer\n",
    "            (p.get_x() + p.get_width() / 2, p.get_height()),  # Position of the label\n",
    "            ha='center', va='bottom',  # Alignment of the label\n",
    "            fontsize=10,  # Font size of the label\n",
    "            color='black'  # Color of the label\n",
    "        )\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for student model only\n",
    "print(\"Student Model Evaluation - Misclassification Distribution:\")\n",
    "generate_misclassification_distribution(student_model, test_loader, label_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tsne(model, test_loader):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating t-SNE Features\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Extract hidden states (features)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[-1]  # Use the last hidden state\n",
    "            cls_embeddings = hidden_states[:, 0, :].cpu().numpy()  # Use [CLS] token embeddings\n",
    "\n",
    "            all_features.extend(cls_embeddings)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_features = np.array(all_features)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "    tsne_results = tsne.fit_transform(all_features)\n",
    "\n",
    "    # Plot t-SNE results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for label in np.unique(all_labels):\n",
    "        indices = all_labels == label\n",
    "        plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], label=label_encoder.inverse_transform([label])[0])\n",
    "    plt.title('t-SNE Visualization of Feature Space')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot t-SNE for the student model\n",
    "plot_tsne(student_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
